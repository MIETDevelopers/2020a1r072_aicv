{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "'''Q1: MovieLens 1M Dataset GroupLens Research provides a number of collections of movie ratings data\n    collected from users of MovieLens in the late 1990s and early 2000s. The data provide movie ratings, \n    movie metadata (genres and year), and demographic data about the users (age, zip code, gender identification,\n    and occupation). Such data is often of interest in the development of recommendation systems based on machine learning\n    algorithms. While we do not explore machine learning techniques in detail in this book, I will show you how to\n    slice and dice datasets like these into the exact form you need. The MovieLens 1M dataset contains 1 million \n    ratings collected from 6,000 users on 4,000 movies. Itâ€™s spread across three tables: ratings, user information,\n    and movie information. After extracting the data from the ZIP file, we can load each table into a pandas DataFrame\n    object using pandas.read_table and perform the following task.\n    \n1.    Perform null values identification in the given dataset.\n\n2.    Identify types of attributes in the dataset.\n\n3.    Plot Box plot and violin plot. (also state the inference of each attribute and also find the outlier in the attribute)\n\n4.    Histogram and identification of overlapping.(also state the inference for each attribute.)\n\n5.    Draw different types of scatter plot.(using seaborn library) \n\n6.    Univariate and multivariate analysis.\n_________________________________________________ '''\n\n\n#1\nimport pandas as pd\n\n# Load ratings, users and movies data into separate pandas DataFrame objects\nratings = pd.read_table('ratings.dat', sep='::', header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python')\nusers = pd.read_table('users.dat', sep='::', header=None, names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'], engine='python')\nmovies = pd.read_table('movies.dat', sep='::', header=None, names=['MovieID', 'Title', 'Genres'], engine='python')\n\n# Identify null values in each DataFrame\nprint(ratings.isnull().sum())\nprint(users.isnull().sum())\nprint(movies.isnull().sum())\n\n\n'''2\nTypes of Attributes:\nThe MovieLens 1M dataset contains the following types of attributes:\n\nUserID: integer\nMovieID: integer\nRating: integer\nTimestamp: integer\nGender: categorical (M or F)\nAge: integer\nOccupation: categorical (0-20)\nZip-code: string\nTitle: string\nGenres: categorical (pipe-separated list of genres\n'''\n\n#3\nimport matplotlib.pyplot as plt\n\n# Box plot of ratings\nratings.boxplot(column=['rating'])\nplt.show()\n\n# Violin plot of age\nusers.violinplot(column=['age'])\nplt.show()\n\n# Identify outliers in the rating column\nq1 = ratings['rating'].quantile(0.25)\nq3 = ratings['rating'].quantile(0.75)\niqr = q3 - q1\noutliers = ratings[(ratings['rating'] < q1 - 1.5*iqr) | (ratings['rating'] > q3 + 1.5*iqr)]\nprint(outliers)\n\n\n#4\nimport seaborn as sns\n\n# Histogram of ages\nusers.hist(column=['age'])\nplt.show()\n\n# KDE plot of ratings for males and females\nsns.kdeplot(ratings[ratings['gender']=='M']['rating'], label='Male')\nsns.kdeplot(ratings[ratings['gender']=='F']['rating'], label='Female')\nplt.xlabel('Rating')\nplt.show()\n\n\n#5\nimport seaborn as sns\n\n# Scatter plot of ratings vs. timestamps\nsns.scatterplot(x='timestamp', y='rating', data=ratings)\nplt.show()\n\n# Scatter plot of age vs. ratings\nsns.scatterplot(x='age', y='rating', data=users)\nplt.show()\n\n# Scatter plot of rating vs. genre\ngenre_ratings = ratings.merge(movies, on='movie_id')[['genres', 'rating']]\ngenre_ratings = genre_ratings.assign(genre=genre_ratings['genres'].str.split('|')).explode('genre')\nsns.scatterplot(x='genre', y='rating', data=genre_ratings)\nplt.xticks(rotation=90)\nplt.show()\n\n\n#6import seaborn as sns\n\n# Univariate analysis of ratings\nprint(ratings['rating'].describe())\n\n# Multivariate analysis of ratings, age, and gender\nsns.boxplot(x='rating', y='age', hue='gender', data=ratings.merge(users, on='user_id'))\nplt.show()\n\n# Multivariate analysis of ratings and genres\ngenre_ratings = ratings.merge(movies, on='movie_id')[['genres', 'rating']]\ngenre_ratings = genre_ratings.assign(genre=genre_ratings['genres'].str.split('|')).explode('genre')\nsns.boxplot(x='genre', y='rating', data=genre_ratings)\nplt.xticks(rotation=90)\nplt.show()\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "'''Q2: Diabetics datasets :                                                                                                         (5 marks)\n\n Data Exploration: This includes inspecting the data, visualizing the data, and cleaning the data. Some of the steps used are as follows:\n\n1. Viewing the data statistics.\n\n2. Finding out the dimensions of the dataset, the variable names, the data types, etc.\n\n3. Checking for null values.\n\n4. Inspecting the target variable using pie plot and count plot.\n\n5. Finding out the correlation among different features using heatmap and the bivariate relation between each pair of features using pair plot.\n\nModel Training: 5 Classification Algorithms have been used to find out the best one. These are Logistic Regression, Support Vector Machine, Random Forest, K-Nearest Neighbours, and Naive Bayes.\n\nIn each of the algorithms, the steps followed are as follows:\n\n1. Importing the library for the algorithm.\n\n2. Creating an instance of the Classifier (with default values of parameters or by specifying certain values in certain cases).\n\n3. Training the model on the train set.\n\n4. Prediction on the test set using the trained model.\n\n5. Calculating the accuracy of the prediction.\n'''\ndf.describe()\n\nprint(df.shape) # dimensions of the dataset\nprint(df.columns) # variable names\nprint(df.info()) # data types\n\nprint(df.isnull().sum()) # number of null values in each variable\n\nprint(df['Outcome'].value_counts()) # distribution of the target variable\nplt.pie(df['Outcome'].value_counts(), labels=['Non-diabetic', 'Diabetic'], autopct='%1.1f%%') # pie plot\nsns.countplot(x='Outcome', data=df) # count plot\n\ncorr = df.corr()\nsns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f')\n\nsns.pairplot(df, hue='Outcome')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}